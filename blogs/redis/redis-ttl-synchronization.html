<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Cache Is Not Load Reduction</title>
  <meta name="description" content="TTL synchronization failure analysis in high-traffic .NET systems." />
  <link rel="stylesheet" href="styles.css" />
  <link rel="canonical" href="https://thuongduong.com/blogs/redis/redis-ttl-synchronization.html" />
  <meta name="robots" content="index, follow">
  <script defer src="script.js"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PT2851LYJ0"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-PT2851LYJ0');
  </script>
</head>

<body>
  <header class="nav">
    <div class="container">
      <div class="logo">Duong Hoai Thuong</div>
      <nav>
        <a href="/">Home</a>
        <a href="../../resume.html">Resume</a>
        <a href="../blog.html">Blog</a>
        <a href="mailto:hoaithuongit0511@outlook.com">Contact</a>
      </nav>
    </div>
  </header>
  <div class="container">
    <h1>Cache Is Not Load Reduction</h1>
    <p>
      TTL synchronization in high-traffic systems can create deterministic
      load spikes — even when cache hit ratio looks healthy.
    </p>

    <div id="toc" class="toc">
      <strong>Table of Contents</strong>
    </div>
    <section>
      <h2 id="incident">1. The Incident</h2>

      <p>
        At 02:13 AM, latency increased from 120ms to 3.4 seconds. Database CPU
        reached 95%. Redis was stable.
      </p>

      <p>Cache hit ratio remained 92%.</p>

      <p>The cache did not fail. Time alignment did.</p>

      <h2 id="architecture">2. Architecture</h2>

      <p>Client → ASP.NET Core (.NET 8) → Redis → SQL Server</p>

      <p>Cache-aside pattern. TTL = 10 minutes. No jitter. No soft refresh.</p>

      <pre><code>
public async Task&lt;UserProfile&gt; GetProfileAsync(Guid userId)
{
    var key = $"user:profile:{userId}";

    var cached = await _cache.GetAsync&lt;UserProfile&gt;(key);
    if (cached != null)
        return cached;

    var profile = await _repository.GetAsync(userId);

    await _cache.SetAsync(key, profile, TimeSpan.FromMinutes(10));
    return profile;
}
</code></pre>
    </section>
    <section>

      <h2 id="math">3. The Mathematical Breakdown</h2>

      <p><strong>Total traffic:</strong> 40,000 requests/second</p>
      <p><strong>TTL:</strong> 600 seconds</p>

      <pre><code>
40,000 × 600 = 24,000,000 requests per TTL window
</code></pre>

      <p>Endpoint accounts for 70% of traffic.</p>

      <pre><code>
40,000 × 70% = 28,000 RPS
28,000 × 5 seconds = 140,000 requests
</code></pre>

      <p>Assume 60% hot-key skew:</p>

      <pre><code>
140,000 × 60% = 84,000 expired-key requests
</code></pre>

      <p>Distributed across 5 seconds:</p>

      <pre><code>
84,000 / 5 = 16,800 RPS
</code></pre>

      <p>Database safe capacity ≈ 5,000 RPS.</p>

      <p>16,800 ÷ 5,000 ≈ 3.36× overload.</p>

      <p>
        The average miss rate was only 3,200 RPS. But systems fail on variance,
        not averages.
      </p>

      <h2 id="threadpool">4. ThreadPool Amplification</h2>

      <p>When expiration wave hits:</p>

      <ul>
        <li>Async awaits spike simultaneously</li>
        <li>Connection pool saturates</li>
        <li>ThreadPool injects workers</li>
        <li>Context switching increases</li>
        <li>Latency persists beyond burst</li>
      </ul>

      <p>
        TTL wave → DB spike → ThreadPool inflation → tail latency explosion.
      </p>
    </section>
    <!-- Distributed Lock -->
    <section class="mb-16">
      <h2 id="distributed-lock">5. Why Distributed Lock failed</h2>
      <pre><code class="language-csharp">
if (await db.LockTakeAsync(lockKey, value, TimeSpan.FromSeconds(5)))
{
    try
    {
        // regenerate
    }
    finally
    {
        await db.LockReleaseAsync(lockKey, value);
    }
}
</code></pre>
      <p>Instead of reducing load, it increased latency variance and lock contention.</p>
    </section>

    <section class="mb-16">
      <h2 id="fix">6. The Real Fix: TTL Jitter</h2>

      <pre><code>
var jitter = Random.Shared.Next(0, 120);
var ttl = TimeSpan.FromMinutes(10)
          + TimeSpan.FromSeconds(jitter);

await db.StringSetAsync(key, value, ttl);
</code></pre>

      <p>84,000 misses distributed across 120 seconds:</p>

      <pre><code>
84,000 / 120 ≈ 700 RPS
</code></pre>

      <p>700 RPS is safe.</p>

      <h2 id="soft-ttl">7. Soft Expiration Strategy</h2>
      <pre><code class="language-csharp">
if (cacheEntry.IsSoftExpired)
{
    _ = Task.Run(() => RefreshAsync(key));
    return cacheEntry.Value;
}
</code></pre>

      <p class="mt-6">
        Users never wait for regeneration. Latency stabilizes.
      </p>
    </section>

    <!-- Conclusion -->
    <section class="mb-16">
      <h2 id="conclusion">8. Conclusion</h2>

      <p class="mb-4">
        Cache design is about <strong>load shaping</strong>, not load
        reduction.
      </p>

      <ul class="list-disc list-inside space-y-2">
        <li>Always apply TTL jitter</li>
        <li>Model worst-case burst mathematically</li>
        <li>Monitor miss-rate derivative</li>
        <li>Use soft expiration</li>
      </ul>
    </section>

    <div class="series-meta">
      <div>
        <strong>Redis Production Series</strong> (1/8)
      </div>
      <div>
        <a href="/blogs/redis/">View full series →</a>
      </div>
    </div>

    <div class="post-nav">
      <a href="./distributed-lock-not-concurrency-control.html" style="text-align: right;">
        <span>Next →</span>
        <strong>Distributed Locks Are Not Concurrency Control</strong>
      </a>

    </div>
    <footer>
      © 2026 — Redis Production Series Written for engineers who measure
      variance.
    </footer>
  </div>
</body>

</html>